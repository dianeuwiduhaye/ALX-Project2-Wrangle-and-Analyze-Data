{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad6e1a",
   "metadata": {},
   "source": [
    "### Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256402b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data in a dataframe\n",
    "df1= pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9639a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9755633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url=' https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response=requests.get(url)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dae2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save HTML to file\n",
    "\n",
    "with open(\"image-predictions.tsv\", mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data in a dataframe\n",
    "df2= pd.read_table('image-predictions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed64453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d53ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = 'A8OdkrUyojEaUMQ4cOWdTsRE8'\n",
    "consumer_secret = 'MoKnjOFS0Y4qCQOooPWDmBMUI8kzFv3FfrJCXwXc3aPIoYSMxk'\n",
    "access_token = '1549735475631489026-K4F7cKx2O5VUbdXl00aQ3tRjG6YGhI'\n",
    "access_secret = 'kj7jOAXyIfIJLlPbPTwXJrchjwkWdDGse1AiWpWkB1ykL'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "# NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "# Twitter API code was sent to this student from a Udacity instructor\n",
    "# Tweet IDs for which to gather additional data via Twitter's API\n",
    "tweet_ids = df1.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet-json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepyException as e:  \n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "with open('tweet-json.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        tweet = json.loads(line)\n",
    "        tweet_id = tweet['id']\n",
    "        retweet_count = tweet['retweet_count']\n",
    "        fav_count = tweet['favorite_count']\n",
    "        df_list.append({'tweet_id':tweet_id,\n",
    "                       'retweet_count': retweet_count,\n",
    "                       'favorite_count': fav_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b59895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27912fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4504a",
   "metadata": {},
   "source": [
    "# Assesing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e83e7a",
   "metadata": {},
   "source": [
    "In this section I will asses the data visually and programmaticaly to identify atleast 8 quality issues and 2 tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcd7d95",
   "metadata": {},
   "source": [
    "##### Visual assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9a81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assesing a sample of 20 random records of the twitter archived data.\n",
    "df1.sample(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ddcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assesing a sample of 20 random records of the image predctions data.\n",
    "df2.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assesing a sample of 20 random records of the twitter json text file data.\n",
    "df2.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be2a84",
   "metadata": {},
   "source": [
    "##### Programmatic assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedfb064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e039f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d670d790",
   "metadata": {},
   "source": [
    "### Quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bafaae",
   "metadata": {},
   "source": [
    "1. Many missing values in columns: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, and retweeted_status_timestamp and columns that contain data which is not useful in our Analysis such as Retweets.\n",
    "2. Incorrect datatypes on the ratings columns specifically the rating denominator.\n",
    "3. Correcting some unusual names of dogs such as None, a, an, the.\n",
    "4. Consistency in lower case and upper case naming on records in columns p1, p2, and p3.\n",
    "5. There are incorrect data types, tweet_id column is supposed to be a str, timestamp column is supposed to be datetime datatype.\n",
    "6. Wrong values on rating_denominator column different of 10.\n",
    "7. Outliers on reating_numerator which seems incorrect.\n",
    "8.  Rating denominator and reating numerator can be one columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa4f4b",
   "metadata": {},
   "source": [
    "### Tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3a920",
   "metadata": {},
   "source": [
    "1. Correcting the issue with the dog stages and change the four columns which are  doggo, floofer, pupper,puppo into one columns\n",
    "2. The tweet_id is duplicated in all three tables which means that they can be converted into one table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eaadf",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of the dataframes\n",
    "df1_copy = df1.copy()\n",
    "df2_copy = df2.copy()\n",
    "df3_copy = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d007339",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56667a4a",
   "metadata": {},
   "source": [
    "1. Drop rows in df1_copy table that are retweets.\n",
    "They are the ones with non-null values on retweeted... columns.\n",
    "2. Drop columns with more than 75% of missing values such as the in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, and retweeted_status_timestamp columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afd09f5",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping the retweeted_status_id, retweeted_status_user_id, and retweeted_status_timestamp columns\n",
    "columns = ['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp','in_reply_to_status_id', 'in_reply_to_user_id']\n",
    "df1_copy.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc6933",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094def49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a51a46",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8362e9c",
   "metadata": {},
   "source": [
    "1. Fix quality issue of values on rating_denominator different than 10.\n",
    "2. Fix quality issues with values of rating_numerator that looks too high or weird.\n",
    "3. Combine rating_numerator and rating_denominator in one column names rating\n",
    "4. Drop rating_numerator and rating_denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b528a",
   "metadata": {},
   "source": [
    "##### 1. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d49375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the most common denominator\n",
    "df1_copy.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter out where the denominator is 10\n",
    "df1_copy = df1_copy.query(\"rating_denominator == 10\")\n",
    "len(df1_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ab23f",
   "metadata": {},
   "source": [
    "##### 1. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad9f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2a4b9",
   "metadata": {},
   "source": [
    "##### 2.  Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify the weird values and filter them out\n",
    "df1_copy.rating_numerator.value_counts()\n",
    "\n",
    "# We don't have many values over 15, so I will choose values over 15 are outliers for this feature\n",
    "len(df1_copy.query(\"rating_numerator >= 15\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the value in the rating_numerator over 15\n",
    "df1_copy = df1_copy.query(\"rating_numerator < 15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dee238",
   "metadata": {},
   "source": [
    "##### 2. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e32fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if we have 10 values less than 2333\n",
    "len(df1_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f81606",
   "metadata": {},
   "source": [
    "##### 3. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46630a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the rating numerator and the rating denominator to make the Trating column.\n",
    "df1_copy['rating'] = df1_copy['rating_numerator'] / df1_copy['rating_denominator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e305a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the rating column into float\n",
    "df1_copy['rating'] = df1_copy['rating'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c307d72",
   "metadata": {},
   "source": [
    "##### 3. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce0bbd",
   "metadata": {},
   "source": [
    "##### 4. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c443d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rating numerator and denominator columns\n",
    "columns = ['rating_numerator', 'rating_denominator']\n",
    "df1_copy.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d4df7",
   "metadata": {},
   "source": [
    "##### 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7800244",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff6dd3",
   "metadata": {},
   "source": [
    "Turning doggo, floofer, pupper and puppo columns into a categorical column called dog_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c19064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the 'None' values by empty spaces\n",
    "\n",
    "df1_copy.doggo.replace('None', '', inplace=True)\n",
    "df1_copy.floofer.replace('None', '', inplace=True)\n",
    "df1_copy.pupper.replace('None', '', inplace=True)\n",
    "df1_copy.puppo.replace('None', '', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8107cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the values in one column\n",
    "df1_copy['dog_stage'] = df1_copy.doggo + df1_copy.floofer + df1_copy.pupper + df1_copy.puppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacf0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy['dog_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b27fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling multiple stages\n",
    "df1_copy.loc[df1_copy.dog_stage == 'doggopupper', 'dog_stage'] = 'doggo, pupper'\n",
    "df1_copy.loc[df1_copy.dog_stage == 'doggopuppo', 'dog_stage'] = 'doggo, puppo'\n",
    "df1_copy.loc[df1_copy.dog_stage == 'doggofloofer', 'dog_stage'] = 'doggo, floofer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the doggo, floofer, pupper, puppo columns\n",
    "columns = ['doggo','floofer','pupper','puppo']\n",
    "df1_copy.drop(columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values in dog_stage column\n",
    "df1_copy.loc[df1_copy.dog_stage == '', 'dog_stage'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bcc039",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55640d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777d057",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db41f8",
   "metadata": {},
   "source": [
    "Merge df3_copy and df2_copy dataframes  which are the data from the twitter json txt file and the data of the image predictions  into df1_copy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a0b42",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging df3_copy with df1_copy. \n",
    "df1_copy = pd.merge(df1_copy, df3_copy, on=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging df3_copy with df1_copy\n",
    "# Use inner join because we want to keep only the tweets with images\n",
    "df1_copy = pd.merge(df1_copy, df2_copy, on=['tweet_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0145ca",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6696116c",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18009cbd",
   "metadata": {},
   "source": [
    "Fix the Datatype of timestamp and the tweet_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ba266",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a689ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestamp\n",
    "df1_copy['timestamp'] = pd.to_datetime(df1_copy['timestamp'])\n",
    "\n",
    "#tweet_id\n",
    "df1_copy['tweet_id'] = df1_copy['tweet_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed88012",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0405f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_copy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907bf73f",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a9dd90",
   "metadata": {},
   "source": [
    "Turn the data in columns p1, p2, and p3 to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75247a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy['p1']=df1_copy['p1'].str.lower()\n",
    "df1_copy['p2']=df1_copy['p2'].str.lower()\n",
    "df1_copy['p3']=df1_copy['p3'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d90540",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8f87d",
   "metadata": {},
   "source": [
    "##### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc74b5",
   "metadata": {},
   "source": [
    "1. Identify wrong name of dogs such as 'his', 'a', 'very', 'unacceptable', 'such','the', 'an', among others.\n",
    "2. Replace these values by NaN so they are defined as unknown values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1911b5a",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e57399",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da317a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy['name'] = df1_copy['name'].replace(['None', 'a', 'an', 'the','by','my',], 'No name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af96494",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.name.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8aa505",
   "metadata": {},
   "source": [
    "# Storing clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fed041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_copy.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a92ad",
   "metadata": {},
   "source": [
    "# Analysis and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe63a4",
   "metadata": {},
   "source": [
    "In this section, analyze and visualize your wrangled data. You must produce at least three (3) insights and one (1) visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf74c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dceccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "df=pd.read_csv('twitter_archive_master.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50957126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c5e3c",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d798e",
   "metadata": {},
   "source": [
    "##### What is the relationship between dog_stage and people's interactions either in Likes and Retweets  ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b39136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first we will group the dog_stage data with respect to retweet count and then save it in a new list create a new series \n",
    "df_dog_stage = df.groupby('dog_stage')['retweet_count'].count()\n",
    "df_dog_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b60e06",
   "metadata": {},
   "source": [
    "For this visualization i will be making use of the series just created above to create a bar chart to analyze the rate of dog stages to retweet count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9194e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(np.arange(7), df_dog_stage, color = 'Green')\n",
    "plt.xticks(np.arange(7), ('doggo', 'doggo, floofer ', 'doggo, pupper', 'doggo, puppo', 'floofer', 'pupper','puppo'))\n",
    "plt.xlabel('Dog Stages')\n",
    "plt.ylabel('Retweets counts')\n",
    "plt.title('Dog stages and their Retweets counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec200a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_stage =['doggo','doggo,floofer','doggo,pupper','doggo,puppo ','floofer','pupper','puppo']\n",
    "df1_dog_stage= df.groupby('dog_stage')['favorite_count'].count()\n",
    "df1_dog_stage.plot(kind='bar',title= 'Dog stages and their favorites count',color='Green', figsize=(9,6))\n",
    "plt.xlabel=('Dog_stage')\n",
    "plt.ylabel=('Favorite_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c0ab5f",
   "metadata": {},
   "source": [
    "##### Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2b57e",
   "metadata": {},
   "source": [
    "* The dog stage with the highest retweets and likes is on  the pupper stage.\n",
    "* doggo,floofer and doggo,puppo stages are the least to retweeted and liked.\n",
    "* Lastly, the dogs at pupper stages are the most famous since they are the most retweeted and liked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018818a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
